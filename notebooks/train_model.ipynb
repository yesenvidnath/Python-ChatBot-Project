{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1tB5ZiolGEzahdIQX4F36vp5y0_4g8n_X","authorship_tag":"ABX9TyOp/oV0me61Ej7u9Hjngq+I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"UEhZFIl2qERS","executionInfo":{"status":"ok","timestamp":1716917237784,"user_tz":-330,"elapsed":5242,"user":{"displayName":"Yesen Kandalama","userId":"02462414632984448817"}}},"outputs":[],"source":["# Import necessary libraries\n","import json\n","import time\n","from threading import Thread\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import CountVectorizer\n","from torch.utils.data import Dataset, DataLoader\n","import pickle\n","import os\n","\n","# Add project directory to the system path\n","project_path = '/content/drive/My Drive/ChatBotProject'\n","os.chdir(project_path)\n","\n","# Paths\n","intents_path = 'data/intents.json'\n","user_generated_intents_path = 'data/user_generated_intents.json'\n","model_path = 'models/intent_classifier.pth'\n","label_encoder_path = 'models/label_encoder.pkl'\n","vectorizer_path = 'models/vectorizer.pkl'\n","\n","# Function to load intents\n","def load_intents():\n","    with open(intents_path, 'r') as f:\n","        intents = json.load(f)['intents']\n","    try:\n","        with open(user_generated_intents_path, 'r') as f:\n","            user_generated_intents = json.load(f)['intents']\n","        intents.extend(user_generated_intents)\n","    except (FileNotFoundError, json.JSONDecodeError):\n","        pass\n","    return intents\n","\n","# Function to preprocess data\n","def preprocess_data(intents):\n","    patterns = []\n","    tags = []\n","    for intent in intents:\n","        for pattern in intent['patterns']:\n","            patterns.append(pattern)\n","            tags.append(intent['tag'])\n","    return patterns, tags\n","\n","# Function to retrain the model\n","def retrain_model():\n","    intents = load_intents()\n","    patterns, tags = preprocess_data(intents)\n","\n","    # Convert labels to integers\n","    label_encoder = LabelEncoder()\n","    encoded_tags = label_encoder.fit_transform(tags)\n","\n","    # Tokenization function\n","    def tokenize(text):\n","        return text.split()\n","\n","    # Convert text to vectors\n","    vectorizer = CountVectorizer(tokenizer=tokenize, binary=True)\n","    X = vectorizer.fit_transform(patterns).toarray()\n","    y = encoded_tags\n","\n","    # Create custom dataset\n","    class IntentDataset(Dataset):\n","        def __init__(self, X, y):\n","            self.X = X\n","            self.y = y\n","\n","        def __len__(self):\n","            return len(self.y)\n","\n","        def __getitem__(self, idx):\n","            return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n","\n","    dataset = IntentDataset(X, y)\n","    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n","\n","    # Define the model\n","    class IntentClassifier(nn.Module):\n","        def __init__(self, input_dim, hidden_dim, output_dim):\n","            super(IntentClassifier, self).__init__()\n","            self.fc1 = nn.Linear(input_dim, hidden_dim)\n","            self.relu = nn.ReLU()\n","            self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","        def forward(self, x):\n","            x = self.fc1(x)\n","            x = self.relu(x)\n","            x = self.fc2(x)\n","            return x\n","\n","    input_dim = X.shape[1]\n","    hidden_dim = 128\n","    output_dim = len(set(tags))\n","\n","    model = IntentClassifier(input_dim, hidden_dim, output_dim)\n","\n","    # Define loss and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # Training loop\n","    epochs = 100\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for inputs, labels in dataloader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        if (epoch+1) % 10 == 0:\n","            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(dataloader)}')\n","\n","    # Save the model\n","    torch.save(model.state_dict(), model_path)\n","    print(f'Model saved as {model_path}')\n","\n","    # Save label encoder and vectorizer for future use\n","    with open(label_encoder_path, 'wb') as f:\n","        pickle.dump(label_encoder, f)\n","    with open(vectorizer_path, 'wb') as f:\n","        pickle.dump(vectorizer, f)\n","    print('Label encoder and vectorizer saved.')\n","\n","# Function to run retrain_model periodically\n","def retrain_periodically(interval=600):\n","    while True:\n","        retrain_model()\n","        time.sleep(interval)\n","\n","# Start the retraining thread\n","retrain_thread = Thread(target=retrain_periodically, args=(600,))\n","retrain_thread.start()\n"]}]}